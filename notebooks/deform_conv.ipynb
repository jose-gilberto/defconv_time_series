{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbosa/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/home/gbarbosa/anaconda3/lib/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed =  0.3649280071258545\n",
      "torch.Size([4, 64, 255, 255])\n",
      "speed =  0.02104020118713379\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    " @Time    : 2019/2/20 22:16\n",
    " @Author  : Wang Xin\n",
    " @Email   : wangxin_buaa@163.com\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DeformConv2D(nn.Module):\n",
    "    def __init__(self, inc, outc, kernel_size=3, padding=1, stride=1, bias=None, lr_ratio=1.0):\n",
    "        super(DeformConv2D, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.zero_padding = nn.ZeroPad2d(padding)\n",
    "\n",
    "        # \n",
    "        self.offset_conv = nn.Conv2d(\n",
    "            inc,2 * kernel_size * kernel_size, kernel_size=3, padding=1, stride=stride)\n",
    "        nn.init.constant_(self.offset_conv.weight, 0)  # the offset learning are initialized with zero weights\n",
    "        self.offset_conv.register_backward_hook(self._set_lr)\n",
    "\n",
    "        self.conv = nn.Conv2d(inc, outc, kernel_size=kernel_size, stride=kernel_size, bias=bias)\n",
    "\n",
    "        self.lr_ratio = lr_ratio\n",
    "\n",
    "    def _set_lr(self, module, grad_input, grad_output):\n",
    "        # print('grad input:', grad_input)\n",
    "        new_grad_input = []\n",
    "\n",
    "        for i in range(len(grad_input)):\n",
    "            if grad_input[i] is not None:\n",
    "                new_grad_input.append(grad_input[i] * self.lr_ratio)\n",
    "            else:\n",
    "                new_grad_input.append(grad_input[i])\n",
    "\n",
    "        new_grad_input = tuple(new_grad_input)\n",
    "        # print('new grad input:', new_grad_input)\n",
    "        return new_grad_input\n",
    "\n",
    "    def forward(self, x):\n",
    "        offset = self.offset_conv(x)\n",
    "        dtype = offset.data.type()\n",
    "        ks = self.kernel_size\n",
    "        N = offset.size(1) // 2\n",
    "\n",
    "        if self.padding:\n",
    "            x = self.zero_padding(x)\n",
    "\n",
    "        # (b, 2N, h, w)\n",
    "        p = self._get_p(offset, dtype)\n",
    "\n",
    "        # (b, h, w, 2N)\n",
    "        p = p.contiguous().permute(0, 2, 3, 1)\n",
    "\n",
    "        \"\"\"\n",
    "            if q is float, using bilinear interpolate, it has four integer corresponding position.\n",
    "            The four position is left top, right top, left bottom, right bottom, defined as q_lt, q_rb, q_lb, q_rt\n",
    "        \"\"\"\n",
    "        # (b, h, w, 2N)\n",
    "        q_lt = p.detach().floor()\n",
    "\n",
    "        \"\"\"\n",
    "            Because the shape of x is N, b, h, w, the pixel position is (y, x)\n",
    "            *┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄→y\n",
    "            ┊  .(y, x)   .(y+1, x)\n",
    "            ┊   \n",
    "            ┊  .(y, x+1) .(y+1, x+1)\n",
    "            ┊\n",
    "            ↓\n",
    "            x\n",
    "\n",
    "            For right bottom point, it'x = left top'y + 1, it'y = left top'y + 1\n",
    "        \"\"\"\n",
    "        q_rb = q_lt + 1\n",
    "\n",
    "        \"\"\"\n",
    "            x.size(2) is h, x.size(3) is w, make 0 <= p_y <= h - 1, 0 <= p_x <= w-1\n",
    "        \"\"\"\n",
    "        q_lt = torch.cat([torch.clamp(q_lt[..., :N], 0, x.size(2) - 1), torch.clamp(q_lt[..., N:], 0, x.size(3) - 1)],\n",
    "                         dim=-1).long()\n",
    "\n",
    "        \"\"\"\n",
    "            x.size(2) is h, x.size(3) is w, make 0 <= p_y <= h - 1, 0 <= p_x <= w-1\n",
    "        \"\"\"\n",
    "        q_rb = torch.cat([torch.clamp(q_rb[..., :N], 0, x.size(2) - 1), torch.clamp(q_rb[..., N:], 0, x.size(3) - 1)],\n",
    "                         dim=-1).long()\n",
    "\n",
    "        \"\"\"\n",
    "            For the left bottom point, it'x is equal to right bottom, it'y is equal to left top\n",
    "            Therefore, it's y is from q_lt, it's x is from q_rb\n",
    "        \"\"\"\n",
    "        q_lb = torch.cat([q_lt[..., :N], q_rb[..., N:]], -1)\n",
    "\n",
    "        \"\"\"\n",
    "            y from q_rb, x from q_lt\n",
    "            For right top point, it's x is equal t to left top, it's y is equal to right bottom \n",
    "        \"\"\"\n",
    "        q_rt = torch.cat([q_rb[..., :N], q_lt[..., N:]], -1)\n",
    "\n",
    "        \"\"\"\n",
    "            find p_y <= padding or p_y >= h - 1 - padding, find p_x <= padding or p_x >= x - 1 - padding\n",
    "            This is to find the points in the area where the pixel value is meaningful.\n",
    "        \"\"\"\n",
    "        # (b, h, w, N)\n",
    "        mask = torch.cat([p[..., :N].lt(self.padding) + p[..., :N].gt(x.size(2) - 1 - self.padding),\n",
    "                          p[..., N:].lt(self.padding) + p[..., N:].gt(x.size(3) - 1 - self.padding)], dim=-1).type_as(p)\n",
    "        mask = mask.detach()\n",
    "        # print('mask:', mask)\n",
    "\n",
    "        floor_p = torch.floor(p)\n",
    "        # print('floor_p = ', floor_p)\n",
    "\n",
    "        \"\"\"\n",
    "           when mask is 1, take floor_p;\n",
    "           when mask is 0, take original p.\n",
    "           When thr point in the padding area, interpolation is not meaningful and we can take the nearest\n",
    "           point which is the most possible to have meaningful value.\n",
    "        \"\"\"\n",
    "        p = p * (1 - mask) + floor_p * mask\n",
    "        p = torch.cat([torch.clamp(p[..., :N], 0, x.size(2) - 1), torch.clamp(p[..., N:], 0, x.size(3) - 1)], dim=-1)\n",
    "\n",
    "        \"\"\"\n",
    "            In the paper, G(q, p) = g(q_x, p_x) * g(q_y, p_y)\n",
    "            g(a, b) = max(0, 1-|a-b|)\n",
    "        \"\"\"\n",
    "        # bilinear kernel (b, h, w, N)\n",
    "        g_lt = (1 + (q_lt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_lt[..., N:].type_as(p) - p[..., N:]))\n",
    "        g_rb = (1 - (q_rb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_rb[..., N:].type_as(p) - p[..., N:]))\n",
    "        g_lb = (1 + (q_lb[..., :N].type_as(p) - p[..., :N])) * (1 - (q_lb[..., N:].type_as(p) - p[..., N:]))\n",
    "        g_rt = (1 - (q_rt[..., :N].type_as(p) - p[..., :N])) * (1 + (q_rt[..., N:].type_as(p) - p[..., N:]))\n",
    "\n",
    "        # print('g_lt size is ', g_lt.size())\n",
    "        # print('g_lt unsqueeze size:', g_lt.unsqueeze(dim=1).size())\n",
    "\n",
    "        # (b, c, h, w, N)\n",
    "        x_q_lt = self._get_x_q(x, q_lt, N)\n",
    "        x_q_rb = self._get_x_q(x, q_rb, N)\n",
    "        x_q_lb = self._get_x_q(x, q_lb, N)\n",
    "        x_q_rt = self._get_x_q(x, q_rt, N)\n",
    "\n",
    "        \"\"\"\n",
    "            In the paper, x(p) = ΣG(p, q) * x(q), G is bilinear kernal\n",
    "        \"\"\"\n",
    "        # (b, c, h, w, N)\n",
    "        x_offset = g_lt.unsqueeze(dim=1) * x_q_lt + \\\n",
    "                   g_rb.unsqueeze(dim=1) * x_q_rb + \\\n",
    "                   g_lb.unsqueeze(dim=1) * x_q_lb + \\\n",
    "                   g_rt.unsqueeze(dim=1) * x_q_rt\n",
    "\n",
    "        \"\"\"\n",
    "            x_offset is kernel_size * kernel_size(N) times x. \n",
    "        \"\"\"\n",
    "        x_offset = self._reshape_x_offset(x_offset, ks)\n",
    "\n",
    "        out = self.conv(x_offset)\n",
    "        return out\n",
    "\n",
    "    def _get_p_n(self, N, dtype):\n",
    "        \"\"\"\n",
    "            In torch 0.4.1 grid_x, grid_y = torch.meshgrid([x, y])\n",
    "            In torch 1.0   grid_x, grid_y = torch.meshgrid(x, y)\n",
    "        \"\"\"\n",
    "        p_n_x, p_n_y = torch.meshgrid(\n",
    "            torch.arange(-(self.kernel_size - 1) // 2, (self.kernel_size - 1) // 2 + 1),\n",
    "             torch.arange(-(self.kernel_size - 1) // 2, (self.kernel_size - 1) // 2 + 1))\n",
    "        # (2N, 1)\n",
    "        p_n = torch.cat([torch.flatten(p_n_x), torch.flatten(p_n_y)], 0)\n",
    "        p_n = p_n.view(1, 2 * N, 1, 1).type(dtype)\n",
    "        p_n.requires_grad = False\n",
    "        # print('requires_grad:', p_n.requires_grad)\n",
    "\n",
    "        return p_n\n",
    "\n",
    "    def _get_p_0(self, h, w, N, dtype):\n",
    "        p_0_x, p_0_y = torch.meshgrid(\n",
    "            torch.arange(1, h * self.stride + 1, self.stride),\n",
    "            torch.arange(1, w * self.stride + 1, self.stride))\n",
    "        p_0_x = torch.flatten(p_0_x).view(1, 1, h, w).repeat(1, N, 1, 1)\n",
    "        p_0_y = torch.flatten(p_0_y).view(1, 1, h, w).repeat(1, N, 1, 1)\n",
    "        p_0 = torch.cat([p_0_x, p_0_y], 1).type(dtype)\n",
    "        p_0.requires_grad = False\n",
    "\n",
    "        return p_0\n",
    "\n",
    "    def _get_p(self, offset, dtype):\n",
    "        N, h, w = offset.size(1) // 2, offset.size(2), offset.size(3)\n",
    "\n",
    "        # (1, 2N, 1, 1)\n",
    "        p_n = self._get_p_n(N, dtype)\n",
    "\n",
    "        # (1, 2N, h, w)\n",
    "        p_0 = self._get_p_0(h, w, N, dtype)\n",
    "\n",
    "        p = p_0 + p_n + offset\n",
    "        return p\n",
    "\n",
    "    def _get_x_q(self, x, q, N):\n",
    "        b, h, w, _ = q.size()\n",
    "        padded_w = x.size(3)\n",
    "        c = x.size(1)\n",
    "        # (b, c, h*w)\n",
    "        x = x.contiguous().view(b, c, -1)\n",
    "\n",
    "        # (b, h, w, N)\n",
    "        index = q[..., :N] * padded_w + q[..., N:]  # offset_x*w + offset_y\n",
    "        # (b, c, h*w*N)\n",
    "        index = index.contiguous().unsqueeze(dim=1).expand(-1, c, -1, -1, -1).contiguous().view(b, c, -1)\n",
    "\n",
    "        x_offset = x.gather(dim=-1, index=index).contiguous().view(b, c, h, w, N)\n",
    "\n",
    "        return x_offset\n",
    "\n",
    "    @staticmethod\n",
    "    def _reshape_x_offset(x_offset, ks):\n",
    "        b, c, h, w, N = x_offset.size()\n",
    "        x_offset = torch.cat([x_offset[..., s:s + ks].contiguous().view(b, c, h, w * ks) for s in range(0, N, ks)],\n",
    "                             dim=-1)\n",
    "        x_offset = x_offset.contiguous().view(b, c, h * ks, w * ks)\n",
    "\n",
    "        return x_offset\n",
    "\n",
    "\n",
    "from time import time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(4, 3, 255, 255)\n",
    "\n",
    "    # p_conv = nn.Conv2d(3, 2 * 3 * 3, kernel_size=3, padding=1, stride=1)\n",
    "    # conv = nn.Conv2d(3, 64, kernel_size=3, stride=3, bias=False)\n",
    "    #\n",
    "    # d_conv1 = DeformConv2D(3, 64)\n",
    "    # d_conv2 = DeformConv2D_ori(3, 64)\n",
    "    #\n",
    "    # offset = p_conv(x)\n",
    "    #\n",
    "    # end = time()\n",
    "    # y1 = conv(d_conv1(x, offset))\n",
    "    # end = time() - end\n",
    "    # print('#1 speed = ', end)\n",
    "    #\n",
    "    # end = time()\n",
    "    # y2 = conv(d_conv2(x, offset))\n",
    "    # end = time() - end\n",
    "    # print('#2 speed = ', end)\n",
    "\n",
    "    # mask = (y1 == y2)\n",
    "    # print(mask)\n",
    "    # print(torch.max(mask))\n",
    "    # print(torch.min(mask))\n",
    "\n",
    "    x = torch.randn(4, 3, 255, 255)\n",
    "    d_conv = DeformConv2D(3, 64)\n",
    "    conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    end = time()\n",
    "    y = d_conv(x)\n",
    "    end = time() - end\n",
    "    print('speed = ', end)\n",
    "    print(y.size())\n",
    "\n",
    "    end = time()\n",
    "    y = conv(x)\n",
    "    end = time() - end\n",
    "    print('speed = ', end)\n",
    "\n",
    "    if isinstance(d_conv, nn.Conv2d):\n",
    "        print('Yes')\n",
    "    else:\n",
    "        print('No')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
